{
  "hash": "e2666fdadab77f6784742560e6d799e7",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Model Training and Evaluation\"\n---\n\n::: {#8fb3c51b .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.metrics import cohen_kappa_score, classification_report\n\n# Load data\ndf = pd.read_csv(\"data/ca1-dataset.csv\")\n# Data preparation\nX = df.drop(columns=['Unique-id', 'namea', 'OffTask'])\ny = df['OffTask'].map({'N': 0, 'Y': 1})\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Cross-validation and hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200],\n    'max_depth': [10, 20, None],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\ngrid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=skf)\ngrid_search.fit(X_train, y_train)\n\n# Evaluate best model\nbest_rf = grid_search.best_estimator_\ny_pred = best_rf.predict(X_test)\nprint(\"Cohen Kappa Score:\", round(cohen_kappa_score(y_test, y_pred), 2))\nprint(classification_report(y_test, y_pred))\n\n## Visualize Performance\n\nfrom sklearn.metrics import roc_curve, auc, ConfusionMatrixDisplay\n\n# ROC Curve\nfpr, tpr, _ = roc_curve(y_test, best_rf.predict_proba(X_test)[:, 1])\nroc_auc = auc(fpr, tpr)\n\nplt.figure()\nplt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n# Confusion Matrix\nConfusionMatrixDisplay.from_estimator(best_rf, X_test, y_test)\nplt.title(\"Confusion Matrix\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCohen Kappa Score: 0.49\n              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.99       147\n           1       1.00      0.33      0.50         6\n\n    accuracy                           0.97       153\n   macro avg       0.99      0.67      0.74       153\nweighted avg       0.97      0.97      0.97       153\n\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](model_files/figure-html/cell-2-output-2.png){width=571 height=431}\n:::\n\n::: {.cell-output .cell-output-display}\n![](model_files/figure-html/cell-2-output-3.png){width=504 height=449}\n:::\n:::\n\n\n",
    "supporting": [
      "model_files"
    ],
    "filters": [],
    "includes": {}
  }
}