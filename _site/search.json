[
  {
    "objectID": "model.html",
    "href": "model.html",
    "title": "Model Training and Evaluation",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.metrics import cohen_kappa_score, classification_report\n\n# Load data\ndf = pd.read_csv(\"data/ca1-dataset.csv\")\n# Data preparation\nX = df.drop(columns=['Unique-id', 'namea', 'OffTask'])\ny = df['OffTask'].map({'N': 0, 'Y': 1})\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Cross-validation and hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200],\n    'max_depth': [10, 20, None],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\ngrid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=skf)\ngrid_search.fit(X_train, y_train)\n\n# Evaluate best model\nbest_rf = grid_search.best_estimator_\ny_pred = best_rf.predict(X_test)\nprint(\"Cohen Kappa Score:\", round(cohen_kappa_score(y_test, y_pred), 2))\nprint(classification_report(y_test, y_pred))\n\n## Visualize Performance\n\nfrom sklearn.metrics import roc_curve, auc, ConfusionMatrixDisplay\n\n# ROC Curve\nfpr, tpr, _ = roc_curve(y_test, best_rf.predict_proba(X_test)[:, 1])\nroc_auc = auc(fpr, tpr)\n\nplt.figure()\nplt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n# Confusion Matrix\nConfusionMatrixDisplay.from_estimator(best_rf, X_test, y_test)\nplt.title(\"Confusion Matrix\")\nplt.show()\n\nCohen Kappa Score: 0.49\n              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.99       147\n           1       1.00      0.33      0.50         6\n\n    accuracy                           0.97       153\n   macro avg       0.99      0.67      0.74       153\nweighted avg       0.97      0.97      0.97       153"
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "# Import necessary libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load dataset\ndf = pd.read_csv(\"data/ca1-dataset.csv\")\n\n# Basic data overview\ndf.info()\ndf.describe()\n\n# Class distribution\nplt.figure(figsize=(6,4))\nsns.countplot(x='OffTask', data=df)\nplt.title(\"Class Distribution\")\nplt.show()\n\n# Correlation heatmap\nnumeric_df = df.select_dtypes(include=['float64', 'int64'])\nplt.figure(figsize=(10, 8))\nsns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm')\nplt.title(\"Feature Correlation Matrix\")\nplt.show()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 763 entries, 0 to 762\nData columns (total 27 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   Unique-id             763 non-null    object \n 1   namea                 763 non-null    object \n 2   OffTask               763 non-null    object \n 3   Avgright              763 non-null    float64\n 4   Avgbug                763 non-null    float64\n 5   Avghelp               763 non-null    int64  \n 6   Avgchoice             763 non-null    int64  \n 7   Avgstring             763 non-null    int64  \n 8   Avgnumber             763 non-null    int64  \n 9   Avgpoint              763 non-null    int64  \n 10  Avgpchange            763 non-null    float64\n 11  Avgtime               763 non-null    float64\n 12  AvgtimeSDnormed       763 non-null    float64\n 13  Avgtimelast3SDnormed  763 non-null    float64\n 14  Avgtimelast5SDnormed  763 non-null    float64\n 15  Avgnotright           763 non-null    float64\n 16  Avghowmanywrong-up    763 non-null    float64\n 17  Avghelppct-up         763 non-null    int64  \n 18  Avgwrongpct-up        763 non-null    float64\n 19  Avgtimeperact-up      763 non-null    float64\n 20  AvgPrev3Count-up      763 non-null    float64\n 21  AvgPrev5Count-up      763 non-null    float64\n 22  Avgrecent8help        763 non-null    int64  \n 23  Avg recent5wrong      763 non-null    float64\n 24  Avgmanywrong-up       763 non-null    float64\n 25  AvgasymptoteA-up      763 non-null    int64  \n 26  AvgasymptoteB-up      763 non-null    int64  \ndtypes: float64(15), int64(9), object(3)\nmemory usage: 161.1+ KB"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "Conclusion",
    "section": "",
    "text": "The Random Forest model achieved a Cohen Kappa Score of 0.49, showing moderate agreement between predictions and actual observations.\n\n\n\nUse SMOTE for class imbalance correction.\nExperiment with more complex models (XGBoost, LSTM).\nIncorporate more features and fine-tune hyperparameters."
  },
  {
    "objectID": "conclusion.html#summary",
    "href": "conclusion.html#summary",
    "title": "Conclusion",
    "section": "",
    "text": "The Random Forest model achieved a Cohen Kappa Score of 0.49, showing moderate agreement between predictions and actual observations.\n\n\n\nUse SMOTE for class imbalance correction.\nExperiment with more complex models (XGBoost, LSTM).\nIncorporate more features and fine-tune hyperparameters."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Off-task Behavior Detection",
    "section": "",
    "text": "1 Introduction\nThis project applies machine learning techniques to detect off-task behavior in students based on classroom data. It leverages machine learning models to identify patterns in the data and uses cross-validation for model tuning.\n\n\n2 Exploratory Data Analysis\nI import the necessary libraries to perform exploratory data analysis (EDA). Next, I load the dataset into a dataframe and generate descriptive statistics to understand the distribution and spread of the variables. I visualize the class distribution using a bar chart to identify any imbalance in the target variable. Finally, I create a correlation heatmap to examine relationships between the features and the target variable.\n\n# Import necessary libraries for exploratory data analysis (EDA)\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load the dataset into a pandas DataFrame\ndf = pd.read_csv(\"data/ca1-dataset.csv\")\n\n\n# Display basic information about the dataset (column types, non-null counts)\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 763 entries, 0 to 762\nData columns (total 27 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   Unique-id             763 non-null    object \n 1   namea                 763 non-null    object \n 2   OffTask               763 non-null    object \n 3   Avgright              763 non-null    float64\n 4   Avgbug                763 non-null    float64\n 5   Avghelp               763 non-null    int64  \n 6   Avgchoice             763 non-null    int64  \n 7   Avgstring             763 non-null    int64  \n 8   Avgnumber             763 non-null    int64  \n 9   Avgpoint              763 non-null    int64  \n 10  Avgpchange            763 non-null    float64\n 11  Avgtime               763 non-null    float64\n 12  AvgtimeSDnormed       763 non-null    float64\n 13  Avgtimelast3SDnormed  763 non-null    float64\n 14  Avgtimelast5SDnormed  763 non-null    float64\n 15  Avgnotright           763 non-null    float64\n 16  Avghowmanywrong-up    763 non-null    float64\n 17  Avghelppct-up         763 non-null    int64  \n 18  Avgwrongpct-up        763 non-null    float64\n 19  Avgtimeperact-up      763 non-null    float64\n 20  AvgPrev3Count-up      763 non-null    float64\n 21  AvgPrev5Count-up      763 non-null    float64\n 22  Avgrecent8help        763 non-null    int64  \n 23  Avg recent5wrong      763 non-null    float64\n 24  Avgmanywrong-up       763 non-null    float64\n 25  AvgasymptoteA-up      763 non-null    int64  \n 26  AvgasymptoteB-up      763 non-null    int64  \ndtypes: float64(15), int64(9), object(3)\nmemory usage: 161.1+ KB\n\n\n\n# Generate descriptive statistics to understand the distribution and spread of the data\ndf.describe()\n\n\n\n\n\n\n\n\nAvgright\nAvgbug\nAvghelp\nAvgchoice\nAvgstring\nAvgnumber\nAvgpoint\nAvgpchange\nAvgtime\nAvgtimeSDnormed\n...\nAvghelppct-up\nAvgwrongpct-up\nAvgtimeperact-up\nAvgPrev3Count-up\nAvgPrev5Count-up\nAvgrecent8help\nAvg recent5wrong\nAvgmanywrong-up\nAvgasymptoteA-up\nAvgasymptoteB-up\n\n\n\n\ncount\n763.000000\n763.000000\n763.0\n763.0\n763.0\n763.0\n763.0\n763.000000\n763.000000\n763.000000\n...\n763.0\n763.000000\n763.000000\n763.000000\n763.000000\n763.0\n763.000000\n763.000000\n763.0\n763.0\n\n\nmean\n0.713072\n0.055168\n0.0\n0.0\n0.0\n0.0\n0.0\n0.283065\n14.117770\n0.224450\n...\n0.0\n1.483525\n14.241320\n0.446376\n0.574707\n0.0\n0.914248\n0.044288\n0.0\n0.0\n\n\nstd\n0.394293\n0.184326\n0.0\n0.0\n0.0\n0.0\n0.0\n0.386746\n15.623914\n1.317254\n...\n0.0\n4.361797\n10.366487\n0.796067\n1.097031\n0.0\n1.038397\n0.179562\n0.0\n0.0\n\n\nmin\n0.000000\n0.000000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.000000\n-1.000000\n-1.000000\n...\n0.0\n0.000000\n0.000000\n0.000000\n0.000000\n0.0\n0.000000\n0.000000\n0.0\n0.0\n\n\n25%\n0.500000\n0.000000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.000000\n6.250000\n-0.368185\n...\n0.0\n0.000000\n7.838235\n0.000000\n0.000000\n0.0\n0.000000\n0.000000\n0.0\n0.0\n\n\n50%\n1.000000\n0.000000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.000000\n9.666667\n-0.121190\n...\n0.0\n0.000000\n11.000000\n0.000000\n0.000000\n0.0\n0.750000\n0.000000\n0.0\n0.0\n\n\n75%\n1.000000\n0.000000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.500000\n16.000000\n0.306074\n...\n0.0\n0.750000\n17.080128\n0.500000\n0.500000\n0.0\n1.500000\n0.000000\n0.0\n0.0\n\n\nmax\n1.000000\n1.000000\n0.0\n0.0\n0.0\n0.0\n0.0\n1.000000\n205.000000\n13.541537\n...\n0.0\n47.666667\n114.333333\n3.000000\n5.000000\n0.0\n5.000000\n1.000000\n0.0\n0.0\n\n\n\n\n8 rows × 24 columns\n\n\n\n\n# Visualize the distribution of the target variable ('OffTask') to check for class imbalance\nplt.figure(figsize=(6,4))\nsns.countplot(x='OffTask', data=df)\nplt.title(\"Class Distribution\")\nplt.show()\n\n\n\n\n\n\n\n\n\n# Calculate and visualize correlations between numerical features\nnumeric_df = df.select_dtypes(include=['float64', 'int64'])\nplt.figure(figsize=(10, 8))\nsns.heatmap(numeric_df.corr(), annot=False, cmap='coolwarm')\nplt.title(\"Feature Correlation Matrix\")\nplt.show()\n\n\n\n\n\n\n\n\nThe dataset consists of 763 entries and 27 columns, encompassing both numerical and categorical features.\nA review of the dataset reveals no missing values across columns, confirming data completeness. The dataset contains 15 float columns, 9 integer columns, and 3 object columns.\nDescriptive statistics highlight key patterns in the data: - ‘Avgright’ (average correctness) has a mean of 0.71, indicating students are often correct, with a standard deviation of 0.39. - ‘Avgbug’ (average errors) shows minimal occurrence, with a mean of 0.05. - Several features, such as ‘Avghelp’, ‘Avgchoice’, ‘Avgstring’, ‘Avgnumber’, ‘Avgpoint’, and ‘AvgasymptoteA-up/B-up’, consist entirely of zeros, suggesting they may be uninformative and could be removed during preprocessing. - The average time (‘Avgtime’) has a wide range, from -1 to 205, with a mean of 14.12 and notable variance (std = 15.62). - Features like ‘AvgtimeSDnormed’ and ‘Avgpchange’ exhibit both negative and positive values, which may indicate normalized or scaled data points.\nA bar chart of the target variable (‘OffTask’) highlights potential class imbalance, warranting further attention to address skewed distributions in model development.\nA correlation heatmap is generated to visualize relationships between numerical features. Metrics such as ‘Avgtime’, ‘Avgtimeperact-up’, and ‘AvgPrev5Count-up’ may reveal insights into patterns of off-task behavior.\nThe EDA process identifies redundant features with zero variance and confirms the dataset is well-structured for further preprocessing and model development. Addressing these redundant features will help streamline model performance and reduce unnecessary complexity.\n\n\n3 Model Training & Evaluation\nI import the necessary libraries to train and evaluate multiple machine learning models. The dataset is prepared by removing non-predictive columns and eliminating features that contain only zero values.\nTo address class imbalance, I apply SMOTE (Synthetic Minority Over-sampling Technique) within each training fold, ensuring that synthetic samples are generated exclusively from the training data. This prevents data leakage and helps the models better recognize patterns in the minority class.\nI define three classifiers – Random Forest, Logistic Regression, and Support Vector Machine (SVM) – with class weights adjusted to mitigate the effects of class imbalance. For the Random Forest model, I implement a hyperparameter grid to fine-tune the model during training.\nI employ Stratified Group K-Fold cross-validation to maintain balanced class distributions across folds while accounting for group dependencies in the dataset. Within each fold, I apply GridSearchCV to optimize model parameters and evaluate performance on the test set.\nModel performance is assessed using the Cohen’s Kappa score and a classification report. The results for each classifier are aggregated, providing insights into overall performance across the cross-validation folds.\n\nfrom sklearn.model_selection import StratifiedGroupKFold, GridSearchCV\nfrom sklearn.metrics import cohen_kappa_score, classification_report\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import Pipeline\nfrom imblearn.over_sampling import SMOTE\nimport numpy as np\nimport pandas as pd\n\n# Data Preparation\nX = df.drop(columns=['Unique-id', 'OffTask', 'namea'])\ny = df['OffTask'].map({'N': 0, 'Y': 1})  # Map labels to binary (0, 1)\ngroups = df['namea']  # Grouping variable\n\n# Remove columns with all 0 values\nX = X.loc[:, (X != 0).any(axis=0)]\n\n# Define classifiers\nclassifiers = {\n    'Random Forest': RandomForestClassifier(class_weight='balanced'),\n    'Logistic Regression': LogisticRegression(max_iter=1000, class_weight='balanced'),\n    'SVM': SVC(probability=True, class_weight='balanced')\n}\n\n# Hyperparameter grid for Random Forest\nparam_grid_rf = {\n    'classifier__n_estimators': [100, 200],\n    'classifier__max_depth': [10, 20, None],\n    'classifier__min_samples_split': [2, 5, 10],\n    'classifier__min_samples_leaf': [1, 2, 4]\n}\n\n# Stratified Group KFold\ngkf = StratifiedGroupKFold(n_splits=5)\nresults = {}\n\n# Model Training and Evaluation Loop\nfor name, classifier in classifiers.items():\n    pipeline = Pipeline(steps=[\n        ('classifier', classifier)\n    ])\n    \n    param_grid = param_grid_rf if name == 'Random Forest' else {}\n\n    # Store results\n    fold_scores = []\n    y_true_all, y_pred_all = [], []\n\n    for train_idx, test_idx in gkf.split(X, y, groups):\n        # Train-test split\n        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n\n        # Apply SMOTE only to the training data\n        smote = SMOTE(random_state=42)\n        X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n\n        # Perform GridSearchCV\n        grid_search = GridSearchCV(pipeline, param_grid, cv=3)\n        grid_search.fit(X_train_res, y_train_res)\n\n        # Make predictions on the test set\n        y_pred = grid_search.best_estimator_.predict(X_test)\n\n        # Store results for evaluation\n        fold_scores.append(cohen_kappa_score(y_test, y_pred))\n        y_true_all.extend(y_test)\n        y_pred_all.extend(y_pred)\n    \n    # Final performance metrics\n    overall_kappa = cohen_kappa_score(y_true_all, y_pred_all)\n    overall_report = classification_report(y_true_all, y_pred_all)\n\n    # Save Results\n    results[name] = {\n        'mean_kappa': np.mean(fold_scores),\n        'overall_kappa': overall_kappa,\n        'report': overall_report\n    }\n\n    # Print Performance\n    print(f\"\\n{name} Results\")\n    print(f\"Mean Kappa Across Folds: {np.mean(fold_scores):.2f}\")\n    print(f\"Overall Kappa: {overall_kappa:.2f}\")\n    print(overall_report)\n\n\nRandom Forest Results\nMean Kappa Across Folds: 0.17\nOverall Kappa: 0.16\n              precision    recall  f1-score   support\n\n           0       0.96      0.96      0.96       729\n           1       0.19      0.21      0.20        34\n\n    accuracy                           0.93       763\n   macro avg       0.58      0.58      0.58       763\nweighted avg       0.93      0.93      0.93       763\n\n\nLogistic Regression Results\nMean Kappa Across Folds: 0.12\nOverall Kappa: 0.11\n              precision    recall  f1-score   support\n\n           0       0.97      0.78      0.87       729\n           1       0.11      0.56      0.18        34\n\n    accuracy                           0.77       763\n   macro avg       0.54      0.67      0.52       763\nweighted avg       0.94      0.77      0.84       763\n\n\nSVM Results\nMean Kappa Across Folds: 0.18\nOverall Kappa: 0.18\n              precision    recall  f1-score   support\n\n           0       0.98      0.83      0.90       729\n           1       0.14      0.62      0.23        34\n\n    accuracy                           0.82       763\n   macro avg       0.56      0.72      0.57       763\nweighted avg       0.94      0.82      0.87       763\n\n\n\nModel Performance Overview:\n\nRandom Forest:\n\nAchieves an overall accuracy of 93%, but performance on the minority class remains limited, with a recall of 18% and an f1-score of 0.18 for class 1.\nThe overall kappa score is 0.14, indicating poor agreement between predictions and actual labels.\n\nLogistic Regression:\n\nYields an accuracy of 77%, with the minority class recall at 56%, reflecting the model’s ability to identify positive cases. However, low precision for the minority class results in an f1-score of 0.18.\nThe overall kappa score is 0.11, indicating slight agreement and limited predictive power for the minority class.\n\nSVM:\n\nSVM demonstrates the highest minority class recall at 62% but maintains low precision, resulting in an f1-score of 0.23.\nWith an overall accuracy of 82% and a kappa score of 0.18, SVM slightly outperforms the other models in balancing sensitivity to the minority class and overall accuracy.\n\n\nKey Insights: Across all models, performance on the majority class (class 0) remains consistently high, while minority class detection (class 1) continues to present challenges. Despite applying SMOTE and adjusting class weights, low f1-scores and precision for the minority class indicate the need for: - Enhanced resampling techniques (e.g., ADASYN, Tomek links). - Feature engineering to improve class separability. - Exploration of ensemble methods or cost-sensitive learning to refine the model’s ability to detect minority class instances.\nWhile SVM offers the best balance between recall and accuracy, further optimization is required to increase precision and overall model robustness when handling imbalanced datasets.\n\n\n4 Visualizing the Peformance\nI import the necessary libraries to evaluate model performance through Receiver Operating Characteristic (ROC) curves and Area Under the Curve (AUC) metrics. A pipeline is created for each classifier, and the models are trained on the entire dataset without cross-validation to simplify visualization.\nThe models generate probability predictions for the positive class, which are used to calculate the ROC curve and AUC score. The ROC curves for each classifier are plotted to compare performance, with a diagonal reference line representing random guessing.\nThe plot is finalized with titles, axis labels, and a legend to provide a clear visual comparison of model performance across different classifiers.\n\n## Visualize Performance\n\nfrom sklearn.metrics import roc_curve, auc, ConfusionMatrixDisplay\n\n\n# Visualize Performance\nplt.figure(figsize=(10, 7))\n\nfor name, classifier in classifiers.items():\n    # Create a simple pipeline with just the classifier\n    pipeline = Pipeline(steps=[\n        ('classifier', classifier)\n    ])\n    \n    # Fit the pipeline on the entire dataset (no cross-validation for visualization)\n    pipeline.fit(X, y)\n    \n    # Predict probabilities for the positive class\n    y_proba = pipeline.predict_proba(X)[:, 1]\n    \n    # Calculate ROC Curve and AUC\n    fpr, tpr, _ = roc_curve(y, y_proba)\n    roc_auc = auc(fpr, tpr)\n    \n    # Plot ROC Curve for each classifier\n    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n\n# Plot diagonal reference line\nplt.plot([0, 1], [0, 1], linestyle='--', color='grey')\n\n# Finalize plot details\nplt.title('ROC Curve Comparison')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc='lower right')\nplt.show()\n\n\n\n\n\n\n\n\nThe ROC curve highlights notable differences between the models: - Random Forest achieves a perfect AUC of 1.00, indicating overfitting or high reliance on the majority class. - SVM demonstrates strong performance with an AUC of 0.87, suggesting better generalization to minority class patterns. - Logistic Regression achieves an AUC of 0.84, reflecting slightly lower discrimination ability compared to SVM.\nThe visualization underscores the trade-off between sensitivity and specificity, with SVM and Logistic Regression showing promising performance, while Random Forest’s perfect AUC suggests further investigation into overfitting.\n\n\n5 Conclusion\nThe evaluation and visualization of three classifiers – Random Forest, Logistic Regression, and Support Vector Machine (SVM) – reveal significant performance differences, particularly in handling class imbalance.\n\nRandom Forest achieves the highest overall accuracy and a perfect AUC score, but this likely indicates overfitting or an inability to generalize to the minority class. Despite high overall accuracy, the model struggles to detect minority class instances (low recall and f1-score).\nSVM offers the best balance between minority class recall (62%) and overall accuracy, with an AUC of 0.87 suggesting better generalization compared to Random Forest.\nLogistic Regression provides moderate performance, with a recall of 56% for the minority class and an AUC of 0.84, indicating acceptable discrimination but lower precision.\n\nDespite SMOTE application and class weight adjustments, all models exhibit limited precision for the minority class, highlighting the need for further refinement. The ROC curve suggests SVM outperforms the other models in minority class detection, making it the most promising model for deployment.\n\n5.0.1 Future Work\nTo enhance model performance, particularly for the minority class, future efforts will focus on addressing overfitting in Random Forest and improving recall-precision balance in all classifiers.\nKey Areas for Improvement: - Overfitting Mitigation (Random Forest): - Regularize the Random Forest model by limiting the maximum depth and increasing minimum samples per leaf. - Experiment with Balanced Random Forest to reduce reliance on the majority class.\n\nResampling Techniques:\n\nContinue exploring SMOTE variations (e.g., ADASYN) or hybrid approaches (combining oversampling and undersampling).\nApply Tomek Links or Cluster Centroids to remove overlapping majority class samples.\n\nAdvanced Models and Ensemble Methods:\n\nImplement ensemble models such as XGBoost, LightGBM, or CatBoost, which handle imbalanced datasets more effectively.\nInvestigate cost-sensitive learning to penalize misclassification of the minority class.\n\nThreshold Tuning:\n\nAdjust classification thresholds to optimize the precision-recall trade-off, particularly for SVM and Logistic Regression.\nUse Precision-Recall Curves to select operating points that maximize minority class detection.\n\nFeature Engineering:\n\nDerive new features that better separate minority class samples using domain knowledge.\nPerform dimensionality reduction (PCA, LDA) to highlight the most discriminative features.\n\nCross-Validation Refinement:\n\nUse nested cross-validation to tune hyperparameters and reduce overfitting.\nApply stratified k-fold cross-validation with SMOTE applied within each fold to prevent data leakage.\n\n\nBy integrating these improvements, the goal is to enhance the recall and precision of minority class detection while ensuring high overall model accuracy and reduced overfitting, making the models more reliable for real-world deployment."
  }
]